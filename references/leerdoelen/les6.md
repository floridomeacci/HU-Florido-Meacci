6.1 begrijpt de motivatie voor het embedden van data in hoog dimensionale vectoreruimtes
6.2 begrijpt de analogie van een vectorruimte met het opruimen van een kamer
6.3 Heeft een begrip van de curse of dimensionality, en begrijpt hoe dit aan de orde is voor hoog dimensionale vectorruimtes
6.4 begrijpt wat een semantische vector is
6.5 kan de definitie van een vectorruimte passief volgen
6.6 kan de definitie van een metric passief volgen
6.7 begrijpt de manifold hypothesis in relatie tot dimensionality reduction
6.8 begrijpt hoe PCA werkt
6.9 begrijpt definities van orthogonal, normalized en basis in relatie tot PCA
6.10 begrijpt hoe t-SNE werkt
6.11 begrijpt wat een manhattan distance is
6.12 begrijpt wat een ngram is en hoe een countvectorizer werkt

Python:
6.13 kan sklearn.decomposition PCA toepassen
6.14 kan sklearn.manifold TSNE toepassen
6.15 kan pandas .apply() toepassen icm pd.to_datetime() om een datetime object te maken
6.16 kan werken met de @dataclass decorator
6.17 kan werken met transformers.pipeline en huggingface modellen
6.18 kan werken met sentence transformers en embeddings